## Steps to word embedding
<details>
<summary><b>Reveal answer</b></summary>
1. One-hot vectors representing every word<br>2. Use those vectors as input to a 2 layer neural letwork<br>3. Use this neural network to predict the word that comes after the input word.<br>4. Train the network (fit the weight matrices)<br>5. Once you finish training, every word will correspond to a vector (hidden layer) which maximised P(y|x)<br><img src="../../../../../media/paste-75e03c035c1a542e2cd608cc2cfd7448acc96da3.jpg"><br><img src="../../../../../media/paste-37760fa2964cb864e862ba61d5f1eaea3542b1d9.jpg"><br><img src="../../../../../media/paste-278b0768f8de603902895836045788a206bae019.jpg"><br><img src="../../../../../media/paste-d56093c96390315c69b68f0189456f3bf074f925.jpg"><br>
</details>
